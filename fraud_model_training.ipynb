{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2df6ff0-be83-47da-a011-c7257a372cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "# =====================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping\n",
    "from sklearn.metrics import classification_report, average_precision_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feedc120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (6362620, 11)\n",
      "Target distribution:\n",
      " isFraud\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2. Load Dataset\n",
    "# =====================================================\n",
    "df = pd.read_csv(\"data/raw/transactions.csv\")\n",
    "target_col = \"isFraud\"  # 👈 adjust if different\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a875ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3817572, 10)\n",
      "Validation shape: (1272524, 10)\n",
      "Test shape: (1272524, 10)\n"
     ]
    }
   ],
   "source": [
    "# 3. Train/Validation/Test Split\n",
    "# =====================================================\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6fae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preprocessing\n",
    "# =====================================================\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Models & Hyperparameters (reduced for speed)\n",
    "# =====================================================\n",
    "models = {\n",
    "    \"log_reg\": LogisticRegression(max_iter=100, random_state=42),\n",
    "    \"rf\": RandomForestClassifier(random_state=42),\n",
    "    \"xgb\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"log_reg\": {\n",
    "        \"classifier__C\": [0.1, 1],\n",
    "        \"classifier__penalty\": [\"l2\"]\n",
    "    },\n",
    "    \"rf\": {\n",
    "        \"classifier__n_estimators\": [50, 100],\n",
    "        \"classifier__max_depth\": [5, 10]\n",
    "    },\n",
    "    \"xgb\": {\n",
    "       \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15db5a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Tuning log_reg on subset...\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "✅ Best log_reg params: {'classifier__penalty': 'l2', 'classifier__C': 0.1}\n",
      "✅ Best PR-AUC (CV): 0.5731\n",
      "\n",
      "🔹 Tuning rf on subset...\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "✅ Best rf params: {'classifier__n_estimators': 100, 'classifier__max_depth': 5}\n",
      "✅ Best PR-AUC (CV): 0.2415\n",
      "\n",
      "🔹 Tuning xgb on subset...\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:53:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best xgb params: {'classifier__subsample': 0.8, 'classifier__n_estimators': 100, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.2}\n",
      "✅ Best PR-AUC (CV): 0.8848\n"
     ]
    }
   ],
   "source": [
    "# 6. Hyperparameter Tuning on Subset\n",
    "# =====================================================\n",
    "# Subset for faster tuning\n",
    "X_tune, _, y_tune, _ = train_test_split(\n",
    "    X_train, y_train, test_size=0.7, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "X_tune_sub, X_es, y_tune_sub, y_es = train_test_split(\n",
    "    X_tune, y_tune, test_size=0.2, stratify=y_tune, random_state=42\n",
    ")\n",
    "\n",
    "best_params_all = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔹 Tuning {name} on subset...\")\n",
    "\n",
    "    # Build pipeline with the current model\n",
    "    pipe = ImbPipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"classifier\", model),\n",
    "    ])\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=param_grid[name],\n",
    "        n_iter=2,   # very small for speed\n",
    "        scoring=\"average_precision\",\n",
    "        cv=2,       # fewer folds\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # ✅ Do NOT pass eval_set here\n",
    "    search.fit(X_tune_sub, y_tune_sub)\n",
    "\n",
    "    print(f\"✅ Best {name} params: {search.best_params_}\")\n",
    "    print(f\"✅ Best PR-AUC (CV): {search.best_score_:.4f}\")\n",
    "\n",
    "    best_params_all[name] = search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "321446fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[11:57:45] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\quantile_dmatrix.cc:55: Check failed: ref->Info().num_col_ == n_features (5613265 vs. 425793) : Invalid ref DMatrix, different number of features.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m final_pipe = ImbPipeline([\n\u001b[32m      4\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m, preprocessor),\n\u001b[32m      5\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33msmote\u001b[39m\u001b[33m\"\u001b[39m, SMOTE(random_state=\u001b[32m42\u001b[39m)),\n\u001b[32m      6\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m, final_xgb),\n\u001b[32m      7\u001b[39m ])\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Preprocess eval set using the SAME pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mfinal_pipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassifier__eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_es\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_es\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassifier__verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\imblearn\\pipeline.py:526\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    521\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    522\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    523\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    524\u001b[39m             all_params=params,\n\u001b[32m    525\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\sklearn.py:1664\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1659\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mnum_class\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.n_classes_\n\u001b[32m   1661\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1662\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1663\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1664\u001b[39m train_dmatrix, evals = \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1669\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1670\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1673\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1674\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1676\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1677\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1681\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = train(\n\u001b[32m   1684\u001b[39m     params,\n\u001b[32m   1685\u001b[39m     train_dmatrix,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1694\u001b[39m     callbacks=\u001b[38;5;28mself\u001b[39m.callbacks,\n\u001b[32m   1695\u001b[39m )\n\u001b[32m   1697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\sklearn.py:679\u001b[39m, in \u001b[36m_wrap_evaluation_matrices\u001b[39m\u001b[34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[39m\n\u001b[32m    677\u001b[39m         evals.append(train_dmatrix)\n\u001b[32m    678\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m         m = \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m            \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m            \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_qid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m            \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m         evals.append(m)\n\u001b[32m    692\u001b[39m nevals = \u001b[38;5;28mlen\u001b[39m(evals)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\sklearn.py:1137\u001b[39m, in \u001b[36mXGBModel._create_dmatrix\u001b[39m\u001b[34m(self, ref, **kwargs)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m.tree_method, \u001b[38;5;28mself\u001b[39m.device) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.booster != \u001b[33m\"\u001b[39m\u001b[33mgblinear\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_bin\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1140\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[32m   1141\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py:1614\u001b[39m, in \u001b[36mQuantileDMatrix.__init__\u001b[39m\u001b[34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, max_quantile_batches, data_split_mode)\u001b[39m\n\u001b[32m   1594\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1595\u001b[39m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1596\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1607\u001b[39m         )\n\u001b[32m   1608\u001b[39m     ):\n\u001b[32m   1609\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1610\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf data iterator is used as input, data like label should be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1611\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mspecified as batch argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1612\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_quantile_blocks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_quantile_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py:1680\u001b[39m, in \u001b[36mQuantileDMatrix._init\u001b[39m\u001b[34m(self, data, ref, enable_categorical, max_quantile_blocks, **meta)\u001b[39m\n\u001b[32m   1678\u001b[39m it.reraise()\n\u001b[32m   1679\u001b[39m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1680\u001b[39m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1681\u001b[39m \u001b[38;5;28mself\u001b[39m.handle = handle\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py:310\u001b[39m, in \u001b[36m_check_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    299\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    300\u001b[39m \n\u001b[32m    301\u001b[39m \u001b[33;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m \u001b[33;03m    return value from API calls\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\u001b[31mXGBoostError\u001b[39m: [11:57:45] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\quantile_dmatrix.cc:55: Check failed: ref->Info().num_col_ == n_features (5613265 vs. 425793) : Invalid ref DMatrix, different number of features."
     ]
    }
   ],
   "source": [
    "final_xgb = XGBClassifier(**best_params_all[\"xgb\"])\n",
    "\n",
    "final_pipe = ImbPipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"classifier\", final_xgb),\n",
    "])\n",
    "\n",
    "# Preprocess eval set using the SAME pipeline\n",
    "final_pipe.fit(\n",
    "    X_train, y_train,\n",
    "    classifier__eval_set=[(preprocessor.fit_transform(X_es), y_es)],\n",
    "    classifier__verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dbefb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Retraining log_reg on FULL data...\n",
      "Val PR-AUC: 0.5945\n",
      "Val ROC-AUC: 0.9889\n",
      "\n",
      "🚀 Retraining rf on FULL data...\n",
      "Val PR-AUC: 0.0021\n",
      "Val ROC-AUC: 0.6695\n",
      "\n",
      "🚀 Retraining xgb on FULL data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:10:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val PR-AUC: 0.9070\n",
      "Val ROC-AUC: 0.9978\n"
     ]
    }
   ],
   "source": [
    "# 7. Retrain on FULL Training Data with Best Params\n",
    "# =====================================================\n",
    "final_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🚀 Retraining {name} on FULL data...\")\n",
    "\n",
    "    best_params = {\n",
    "        k.replace(\"classifier__\", \"\"): v\n",
    "        for k, v in best_params_all[name].items()\n",
    "    }\n",
    "    model.set_params(**best_params)\n",
    "\n",
    "    pipe = ImbPipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"classifier\", model),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    final_models[name] = pipe\n",
    "\n",
    "    # Validation eval\n",
    "    y_val_pred = pipe.predict_proba(X_val)[:, 1]\n",
    "    print(f\"Val PR-AUC: {average_precision_score(y_val, y_val_pred):.4f}\")\n",
    "    print(f\"Val ROC-AUC: {roc_auc_score(y_val, y_val_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ac9422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Final Test Evaluation ================\n",
      "\n",
      "⭐ Model: log_reg\n",
      "Test PR-AUC: 0.6097\n",
      "Test ROC-AUC: 0.9889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1270882\n",
      "           1       0.23      0.73      0.35      1642\n",
      "\n",
      "    accuracy                           1.00   1272524\n",
      "   macro avg       0.62      0.86      0.68   1272524\n",
      "weighted avg       1.00      1.00      1.00   1272524\n",
      "\n",
      "\n",
      "⭐ Model: rf\n",
      "Test PR-AUC: 0.0020\n",
      "Test ROC-AUC: 0.6697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.34      0.51   1270882\n",
      "           1       0.00      1.00      0.00      1642\n",
      "\n",
      "    accuracy                           0.34   1272524\n",
      "   macro avg       0.50      0.67      0.26   1272524\n",
      "weighted avg       1.00      0.34      0.51   1272524\n",
      "\n",
      "\n",
      "⭐ Model: xgb\n",
      "Test PR-AUC: 0.9124\n",
      "Test ROC-AUC: 0.9993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99   1270882\n",
      "           1       0.09      1.00      0.17      1642\n",
      "\n",
      "    accuracy                           0.99   1272524\n",
      "   macro avg       0.55      0.99      0.58   1272524\n",
      "weighted avg       1.00      0.99      0.99   1272524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Final Test Evaluation\n",
    "# =============================================== ======\n",
    "print(\"\\n================ Final Test Evaluation ================\")\n",
    "for name, model in final_models.items():\n",
    "    y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\n⭐ Model: {name}\")\n",
    "    print(f\"Test PR-AUC: {average_precision_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"Test ROC-AUC: {roc_auc_score(y_test, y_test_pred):.4f}\")\n",
    "    print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88b44249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final model saved as fraud_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# 9. Save Final Best Model\n",
    "# =====================================================\n",
    "final_model = final_models[\"xgb\"]  # 👈 pick best based on metrics\n",
    "joblib.dump(final_model, \"fraud_model.pkl\")\n",
    "print(\"\\n✅ Final model saved as fraud_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RetouchIT-ML-AI-Technical-Assessment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
