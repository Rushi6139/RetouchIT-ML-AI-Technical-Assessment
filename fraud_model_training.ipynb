{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2df6ff0-be83-47da-a011-c7257a372cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "# =====================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping\n",
    "from sklearn.metrics import classification_report, average_precision_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feedc120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (6362620, 11)\n",
      "Target distribution:\n",
      " isFraud\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2. Load Dataset\n",
    "# =====================================================\n",
    "df = pd.read_csv(\"data/raw/transactions.csv\")\n",
    "target_col = \"isFraud\"  # üëà adjust if different\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a875ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3817572, 10)\n",
      "Validation shape: (1272524, 10)\n",
      "Test shape: (1272524, 10)\n"
     ]
    }
   ],
   "source": [
    "# 3. Train/Validation/Test Split\n",
    "# =====================================================\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6fae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preprocessing\n",
    "# =====================================================\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5122f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Models & Hyperparameters (reduced for speed)\n",
    "# =====================================================\n",
    "models = {\n",
    "    \"log_reg\": LogisticRegression(max_iter=100, random_state=42),\n",
    "    \"rf\": RandomForestClassifier(random_state=42),\n",
    "    \"xgb\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"log_reg\": {\n",
    "        \"classifier__C\": [0.1, 1],\n",
    "        \"classifier__penalty\": [\"l2\"]\n",
    "    },\n",
    "    \"rf\": {\n",
    "        \"classifier__n_estimators\": [50, 100],\n",
    "        \"classifier__max_depth\": [5, 10]\n",
    "    },\n",
    "    \"xgb\": {\n",
    "        \"classifier__n_estimators\": [50, 100],\n",
    "        \"classifier__max_depth\": [3, 5],\n",
    "        \"classifier__learning_rate\": [0.1, 0.2],\n",
    "        \"classifier__subsample\": [0.8]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15db5a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Tuning log_reg on subset...\n",
      "\n",
      "üîπ Tuning rf on subset...\n",
      "\n",
      "üîπ Tuning xgb on subset...\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 4 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 407, in pandas_feature_info\n    new_feature_types.append(_pandas_dtype_mapper[dtype.name])\n                             ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 'object'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\imblearn\\pipeline.py\", line 526, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1664, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        missing=self.missing,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<14 lines>...\n        feature_types=self.feature_types,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\sklearn.py\", line 679, in _wrap_evaluation_matrices\n    m = create_dmatrix(\n        data=valid_X,\n    ...<8 lines>...\n        ref=train_dmatrix,\n    )\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1137, in _create_dmatrix\n    return QuantileDMatrix(\n        **kwargs, ref=ref, nthread=self.n_jobs, max_bin=self.max_bin\n    )\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 1614, in __init__\n    self._init(\n    ~~~~~~~~~~^\n        data,\n        ^^^^^\n    ...<12 lines>...\n        max_quantile_blocks=max_quantile_batches,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 1678, in _init\n    it.reraise()\n    ~~~~~~~~~~^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 572, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n    ^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 553, in _handle_exception\n    return fn()\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 640, in <lambda>\n    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n                                              ~~~~~~~~~^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 1654, in next\n    input_data(**self.kwargs)\n    ~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 620, in input_data\n    new, cat_codes, feature_names, feature_types = _proxy_transform(\n                                                   ~~~~~~~~~~~~~~~~^\n        data,\n        ^^^^^\n    ...<2 lines>...\n        self._enable_categorical,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 1707, in _proxy_transform\n    df, feature_names, feature_types = _transform_pandas_df(\n                                       ~~~~~~~~~~~~~~~~~~~~^\n        data, enable_categorical, feature_names, feature_types\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 640, in _transform_pandas_df\n    feature_names, feature_types = pandas_feature_info(\n                                   ~~~~~~~~~~~~~~~~~~~^\n        data, meta, feature_names, feature_types, enable_categorical\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 409, in pandas_feature_info\n    _invalid_dataframe_dtype(data)\n    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 372, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:type: object, nameOrig: object, nameDest: object\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mxgb\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     45\u001b[39m     fit_params = {\n\u001b[32m     46\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclassifier__eval_set\u001b[39m\u001b[33m\"\u001b[39m: [(X_es, y_es)],\n\u001b[32m     47\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclassifier__verbose\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     48\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tune_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tune_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Best \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Best PR-AUC (CV): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch.best_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1028\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1026\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 4 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 407, in pandas_feature_info\n    new_feature_types.append(_pandas_dtype_mapper[dtype.name])\n                             ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 'object'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\imblearn\\pipeline.py\", line 526, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1664, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        missing=self.missing,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<14 lines>...\n        feature_types=self.feature_types,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\sklearn.py\", line 679, in _wrap_evaluation_matrices\n    m = create_dmatrix(\n        data=valid_X,\n    ...<8 lines>...\n        ref=train_dmatrix,\n    )\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1137, in _create_dmatrix\n    return QuantileDMatrix(\n        **kwargs, ref=ref, nthread=self.n_jobs, max_bin=self.max_bin\n    )\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 1614, in __init__\n    self._init(\n    ~~~~~~~~~~^\n        data,\n        ^^^^^\n    ...<12 lines>...\n        max_quantile_blocks=max_quantile_batches,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 1678, in _init\n    it.reraise()\n    ~~~~~~~~~~^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 572, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n    ^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 553, in _handle_exception\n    return fn()\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 640, in <lambda>\n    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n                                              ~~~~~~~~~^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 1654, in next\n    input_data(**self.kwargs)\n    ~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\core.py\", line 620, in input_data\n    new, cat_codes, feature_names, feature_types = _proxy_transform(\n                                                   ~~~~~~~~~~~~~~~~^\n        data,\n        ^^^^^\n    ...<2 lines>...\n        self._enable_categorical,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 1707, in _proxy_transform\n    df, feature_names, feature_types = _transform_pandas_df(\n                                       ~~~~~~~~~~~~~~~~~~~~^\n        data, enable_categorical, feature_names, feature_types\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 640, in _transform_pandas_df\n    feature_names, feature_types = pandas_feature_info(\n                                   ~~~~~~~~~~~~~~~~~~~^\n        data, meta, feature_names, feature_types, enable_categorical\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 409, in pandas_feature_info\n    _invalid_dataframe_dtype(data)\n    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\RetouchIT-ML-AI-Technical-Assessment\\Lib\\site-packages\\xgboost\\data.py\", line 372, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:type: object, nameOrig: object, nameDest: object\n"
     ]
    }
   ],
   "source": [
    "# 6. Hyperparameter Tuning on Subset\n",
    "# =====================================================\n",
    "# Subset for faster tuning\n",
    "X_tune, _, y_tune, _ = train_test_split(\n",
    "    X_train, y_train, test_size=0.7, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "X_tune_sub, X_es, y_tune_sub, y_es = train_test_split(\n",
    "    X_tune, y_tune, test_size=0.2, stratify=y_tune, random_state=42\n",
    ")\n",
    "\n",
    "best_params_all = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîπ Tuning {name} on subset...\")\n",
    "\n",
    "    pipe = ImbPipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"classifier\", XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,  # suppress warnings\n",
    "        eval_metric=\"aucpr\"       # avoids 'eval_metric' error\n",
    "    )),\n",
    "])\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_grid[name],\n",
    "    n_iter=2,   # very small for speed\n",
    "    scoring=\"average_precision\",\n",
    "    cv=2,       # fewer folds\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "fit_params = {}\n",
    "if name == \"xgb\":\n",
    "    fit_params = {\n",
    "        \"classifier__eval_set\": [(X_es, y_es)],\n",
    "        \"classifier__verbose\": False\n",
    "    }\n",
    "\n",
    "search.fit(X_tune_sub, y_tune_sub, **fit_params)\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Best {name} params: {search.best_params_}\")\n",
    "print(f\"‚úÖ Best PR-AUC (CV): {search.best_score_:.4f}\")\n",
    "\n",
    "best_params_all[name] = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbefb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Final Test Evaluation ================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 7. Final Test Evaluation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# =====================================================\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m================ Final Test Evaluation ================\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbest_models\u001b[49m.items():\n\u001b[32m      5\u001b[39m     y_test_pred = model.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m      6\u001b[39m     test_pr_auc = average_precision_score(y_test, y_test_pred)\n",
      "\u001b[31mNameError\u001b[39m: name 'best_models' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. Retrain on FULL Training Data with Best Params\n",
    "# =====================================================\n",
    "final_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüöÄ Retraining {name} on FULL data...\")\n",
    "\n",
    "    best_params = {\n",
    "        k.replace(\"classifier__\", \"\"): v\n",
    "        for k, v in best_params_all[name].items()\n",
    "    }\n",
    "    model.set_params(**best_params)\n",
    "\n",
    "    pipe = ImbPipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"classifier\", model),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    final_models[name] = pipe\n",
    "\n",
    "    # Validation eval\n",
    "    y_val_pred = pipe.predict_proba(X_val)[:, 1]\n",
    "    print(f\"Val PR-AUC: {average_precision_score(y_val, y_val_pred):.4f}\")\n",
    "    print(f\"Val ROC-AUC: {roc_auc_score(y_val, y_val_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9422b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 7. Model Selection\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# -------------------\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Pick the model with best balance of PR-AUC and low false positives\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m final_model = \u001b[43mbest_models\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mlog_reg\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# Example: logistic regression chosen\u001b[39;00m\n\u001b[32m      6\u001b[39m y_pred = final_model.predict(X_test)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, classification_report(y_test, y_pred))\n",
      "\u001b[31mNameError\u001b[39m: name 'best_models' is not defined"
     ]
    }
   ],
   "source": [
    "# 8. Final Test Evaluation\n",
    "# =====================================================\n",
    "print(\"\\n================ Final Test Evaluation ================\")\n",
    "for name, model in final_models.items():\n",
    "    y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\n‚≠ê Model: {name}\")\n",
    "    print(f\"Test PR-AUC: {average_precision_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"Test ROC-AUC: {roc_auc_score(y_test, y_test_pred):.4f}\")\n",
    "    print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b44249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Save Final Best Model\n",
    "# =====================================================\n",
    "final_model = final_models[\"xgb\"]  # üëà pick best based on metrics\n",
    "joblib.dump(final_model, \"fraud_model.pkl\")\n",
    "print(\"\\n‚úÖ Final model saved as fraud_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RetouchIT-ML-AI-Technical-Assessment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
